# -*- coding: utf-8 -*-
"""Fake news Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Se2XOmuAAU1v91ThGaJA-1ifYEGAaeg

About the dataset:
1. id: unique id for a news article
2. title: the title of a news article
3. author: author of the news article
4. text: the text of the article' could be incomplete
5. label: a label that mark wheather the news article is real or fake

1 : Fake News
0 : real News
"""

# Importing the dependencies
import numpy as np
import pandas as pd
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

import nltk
nltk.download('stopwords')

## printing the stop words
print(stopwords.words('english'))

news_dataset = pd.read_csv('/content/train.csv')

"""DAta Pre-Processing"""

news_dataset.shape

# print the first 5 rows of the data frame
news_dataset.head()

# counting the number of missing values in the dataset
news_dataset.isnull().sum()

#replacing the null  values with empty string
news_dataset = news_dataset.fillna('')

#merging the author name and news tiltle
news_dataset['content'] = news_dataset['author']+ ' '+ news_dataset['title']

print(news_dataset['content'])

# separating the data & label
x = news_dataset.drop(columns = 'label',axis=1)
y = news_dataset['label']

print(x)
print(y)

"""Stemming:
Stemming is the process of reducing a words to its root word

example:
actor, actress, acting --> act

"""

port_stem = PorterStemmer()

def stemming(content):
  stemmed_content = re.sub('[^a-zA-z]' ,' ', content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)
  return stemmed_content

news_dataset['content'] = news_dataset['content'].apply(stemming)

print(news_dataset['content'])

# seaparating the data and the label
x = news_dataset['content'].values
y = news_dataset['label'].values

print(x)

print(y)

y.shape

x.shape

#converting the textual data to numerical data
vectorizer = TfidfVectorizer()
vectorizer.fit(x)

x = vectorizer.transform(x)

print(x)

"""Splitting the dataset to training & the test data

"""

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, stratify=y, random_state=2)

"""Training the model : Logistic Regression"""

model = LogisticRegression()

model.fit(x_train, y_train)

"""Evaluation"""

#Accuracy score on the training data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction, y_train)

print('Accuracy score of training data :', training_data_accuracy)

#accuracy on test data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction, y_test)

print('Accuracy score of the test data : ', test_data_accuracy)

"""Making a predictive Sysytem"""

x_news = x_test[10]
prediction = model.predict(x_news)
print(prediction)
if(prediction[0] == 0):
  print('The news is real')
else:
  print('The news is fake')

print(y_test[10])

